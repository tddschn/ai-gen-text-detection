{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61542,"databundleVersionId":7516023,"sourceType":"competition"},{"sourceId":6851361,"sourceType":"datasetVersion","datasetId":3938197},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256},{"sourceId":7082713,"sourceType":"datasetVersion","datasetId":4039374},{"sourceId":7246053,"sourceType":"datasetVersion","datasetId":4197568},{"sourceId":7264407,"sourceType":"datasetVersion","datasetId":3954249,"isSourceIdPinned":true},{"sourceId":7456307,"sourceType":"datasetVersion","datasetId":4050356},{"sourceId":159219517,"sourceType":"kernelVersion"}],"dockerImageVersionId":30636,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#install libs\nimport pickle\nfrom leven_search import LevenSearch, EditCost, EditCostConfig, GranularEditCostConfig\n\nwith open('/kaggle/usr/lib/install_levenshtein_search_library/leven_search.pkl', 'rb') as file:\n    lev_search = pickle.load(file)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Add all imports \nimport os\nimport gc\nimport re\nimport sys\nimport torch\nimport datasets\nimport transformers\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer, PreTrainedTokenizerFast\nfrom tokenizers import ( decoders, models, normalizers, pre_tokenizers, processors, trainers, Tokenizer,)\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfrom collections import Counter\nfrom itertools import chain\n\nfrom tqdm.auto import tqdm\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import train_test_split\n\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.linear_model import LinearRegression  #0.925\n# from sklearn.linear_model import SGDClassifier #0.42\nfrom sklearn.preprocessing import MaxAbsScaler\n# from sklearn.linear_model import SGDRegressor\nfrom sklearn.linear_model import LogisticRegression\n\n\nfrom sklearn.svm import LinearSVR\nfrom scipy.sparse import vstack as spvstack\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import roc_auc_score\nfrom transformers import EarlyStoppingCallback\nfrom collections import defaultdict\n\nfrom tqdm import tqdm\ntqdm.pandas()\n\n#disable wandb\nimport wandb\nwandb.init(mode=\"disabled\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#spell checker code \ndef sentence_correcter(text):\n    wrong_words = []\n    correct_words = dict()\n\n    word_list = re.findall(r'\\b\\w+\\b|[.,\\s]', text)\n\n    for t in word_list:\n        correct_word = t\n\n        if len(t)>2:\n            result = lev_search.find_dist(t, max_distance=0)\n            result = list(result.__dict__['words'].values())\n\n            if len(result) == 0:\n                result = lev_search.find_dist(t, max_distance=1)\n                result = list(result.__dict__['words'].values())\n                if len(result):\n                    correct_word = result[0].word\n                    wrong_words.append((t, result))\n\n        correct_words[t] = correct_word\n\n    dict_freq = defaultdict(lambda :0)           \n    for wrong_word in wrong_words:\n        _, result = wrong_word\n\n        for res in result:\n            updates = res.updates\n            parts = str(updates[0]).split(\" -> \")\n            if len(parts) == 2:\n                from_char = parts[0]\n                to_char = parts[1]\n                dict_freq[(from_char, to_char)] += 1\n\n    if len(dict_freq):\n        max_key = max(dict_freq, key=dict_freq.get)\n        count = dict_freq[max_key]\n    else:\n        count = 0\n\n    if count > 0.06*len(text.split()):\n        gec = GranularEditCostConfig(default_cost=10, edit_costs=[EditCost(max_key[0], max_key[1], 1)])\n\n        for wrong_word in wrong_words:\n            word, _ = wrong_word\n            result = lev_search.find_dist(word, max_distance=9, edit_cost_config=gec)\n            result = list(result.__dict__['words'].values())\n            if len(result):\n                correct_words[word] = result[0].word\n            else:\n                correct_word = word\n\n\n    correct_sentence = []\n    for t in word_list:\n        correct_sentence.append(correct_words[t])\n\n    return \"\".join(correct_sentence)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T14:00:28.866002Z","iopub.execute_input":"2024-01-21T14:00:28.866297Z","iopub.status.idle":"2024-01-21T14:00:28.870933Z","shell.execute_reply.started":"2024-01-21T14:00:28.866271Z","shell.execute_reply":"2024-01-21T14:00:28.87006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define general use methods \n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))  \n\n\nmodel_checkpoint_base = \"/mnt/beegfs/xchen87/ai-gen/data/distilroberta-base/distilroberta-base\"\nmodel_checkpoint_infer = \"/mnt/beegfs/xchen87/ai-gen/data/detect-llm-models/distilroberta-finetuned_v5/checkpoint-13542\"\n\ntokenizer_infer = AutoTokenizer.from_pretrained(model_checkpoint_infer)\ntokenizer_train = AutoTokenizer.from_pretrained(model_checkpoint_base)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:03:00.733748Z","iopub.execute_input":"2024-01-11T12:03:00.734151Z","iopub.status.idle":"2024-01-11T12:03:01.119876Z","shell.execute_reply.started":"2024-01-11T12:03:00.734117Z","shell.execute_reply":"2024-01-11T12:03:01.118962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define data reading methods \n\ndef read_sub():\n    return pd.read_csv('/mnt/beegfs/xchen87/ai-gen/data/llm-detect-ai-generated-text/sample_submission.csv')\n\ndef read_test():\n        return pd.read_csv('/mnt/beegfs/xchen87/ai-gen/data/llm-detect-ai-generated-text/test_essays.csv')\n\ndef read_dummy_test():\n    t =  pd.read_csv('/mnt/beegfs/xchen87/ai-gen/data/daigt-v2-train-dataset/train_v2_drcat_02.csv').tail(9000)\n    t['id'] = range(0, len(t))\n    t = t[['id', 'text']]\n    return t\n\n\ndef append_train_from_sub_phase(org_train_data, train_from_sub):\n    \n    train_from_sub.drop('generated', axis=1, inplace=True)\n    train_from_sub.reset_index(drop=True, inplace=True)\n\n    train_from_sub = train_from_sub[['text', 'label']]\n    \n    train =  pd.concat([org_train_data, train_from_sub])\n    \n    return train\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:03:01.152449Z","iopub.execute_input":"2024-01-11T12:03:01.152872Z","iopub.status.idle":"2024-01-11T12:03:01.170279Z","shell.execute_reply.started":"2024-01-11T12:03:01.152843Z","shell.execute_reply":"2024-01-11T12:03:01.16901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define readig for text categorization\ndef filter_dataframe(df, category):\n    # Filter the DataFrame for the specified category or NaN in 'prompt_name'\n    filtered_df = df[(df['prompt_name'] == category) | (df['prompt_name'].isna())]\n    return filtered_df\n\ndef filter_dataframe_single_category(df, category):\n    # Filter the DataFrame for the specified category in 'prompt_name'\n    filtered_df = df[df['prompt_name'] == category]\n    return filtered_df\n\ndef standardize_categories(df):\n    # Standardize the category name\n    df['prompt_name'] = df['prompt_name'].str.replace('\"A Cowboy Who Rode the Waves\"', 'A Cowboy Who Rode the Waves', regex=False)\n    return df\n\ndef assign_category(row):\n    if row['prompt_id'] == 1:\n        return \"Does the electoral college work?\"\n    elif row['prompt_id'] == 0:\n        return \"Car-free cities\"\n    else:\n        return None  # or some default value\n\n    \ndef read_train_all():\n    train = pd.read_csv(\"/mnt/beegfs/xchen87/ai-gen/data/daigt-v2-train-dataset/train_v2_drcat_02.csv\")\n    train = train[['text', 'prompt_name', 'label']]\n    train = standardize_categories(train)\n\n    train_old =  pd.read_csv(\"/mnt/beegfs/xchen87/ai-gen/data/llm-detect-ai-generated-text/train_essays.csv\")\n    train_old.rename(columns={'generated': 'label'}, inplace=True)\n    train_old['prompt_name'] = train_old.apply(assign_category, axis=1)\n    train_old = train_old[['text', 'prompt_name', 'label']]\n    \n    lm_7b =  pd.read_csv(\"/mnt/beegfs/xchen87/ai-gen/data/llm-mistral-7b-instruct-texts/Mistral7B_CME_v7.csv\")\n    lm_ali_1 =  pd.read_csv(\"/mnt/beegfs/xchen87/ai-gen/data/llm-dataset/gen_llm_fac_v1.csv\")\n    #lm_ali_2 =  pd.read_csv(\"/mnt/beegfs/xchen87/ai-gen/data/llm-dataset/gen_llm_elec_v1.csv\")\n    #lm_ali_3 =  pd.read_csv(\"/mnt/beegfs/xchen87/ai-gen/data/llm-dataset/gen_llm_car_free_v1.csv\")\n    lm_ali_4 =  pd.read_csv(\"/mnt/beegfs/xchen87/ai-gen/data/llm-dataset/gen_llm_exploring_venus_v1.csv\")\n    lm_ali_5 =  pd.read_csv(\"/mnt/beegfs/xchen87/ai-gen/data/llm-dataset/gen_llm_face_on_mars_v1.csv\")\n    lm_ali_6 =  pd.read_csv(\"/mnt/beegfs/xchen87/ai-gen/data/llm-dataset/gen_llm_driveless_cars_v1.csv\")\n    lm_ali_7 =  pd.read_csv(\"/mnt/beegfs/xchen87/ai-gen/data/llm-dataset/gen_llm_cowboy_v1.csv\")\n    lm_ali_8 =  pd.read_csv(\"/mnt/beegfs/xchen87/ai-gen/data/llm-dataset/gen_llm_cowboy_v2.csv\")\n    #lm_ali_9 =  pd.read_csv(\"/mnt/beegfs/xchen87/ai-gen/data/llm-dataset/gen_llm_face_on_mars_v2.csv\")\n    gemini = pd.read_csv(\"/mnt/beegfs/xchen87/ai-gen/data/gemini-pro-llm-daigt/gemini_pro_llm_text.csv\")\n    gemini = gemini[gemini['typos']==\"no\"]\n    #lm_data = pd.concat([lm_7b, lm_ali_1, lm_ali_2, lm_ali_3,lm_ali_4,lm_ali_5,lm_ali_6,lm_ali_7,lm_ali_8,lm_ali_9,gemini], ignore_index=True)\n    lm_data = pd.concat([lm_7b, lm_ali_1, lm_ali_4,lm_ali_5,lm_ali_6,lm_ali_7,lm_ali_8,lm_ali_8,gemini], ignore_index=True)\n\n    lm_data.rename(columns={'generated': 'label'}, inplace=True)\n    del gemini\n    gc.collect()\n    lm_data = lm_data[['text', 'prompt_name', 'label']]\n    lm_data = standardize_categories(lm_data)\n    train_old = standardize_categories(train_old)\n    \n    train =  pd.concat([train, lm_data, train_old])\n    return train, lm_data, train_old","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define PBE Tokenizer class and related methods\n\nclass BPETokenizer:\n    ST = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n    \n    def __init__(\n        self,\n        vocab_size,\n    ):\n        self.vocab_size = vocab_size\n        self.tok = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n        self.tok.normalizer = normalizers.Sequence([normalizers.NFC()])\n        self.tok.pre_tokenizer = pre_tokenizers.ByteLevel()\n        \n    @classmethod\n    def chunk_dataset(cls, dataset, chunk_size=1_000):\n        for i in range(0, len(dataset), chunk_size):\n            yield dataset[i : i + chunk_size][\"text\"]\n        \n    def train(self, data):\n        trainer = trainers.BpeTrainer(vocab_size=self.vocab_size, special_tokens=self.ST)\n        dataset = Dataset.from_pandas(data[[\"text\"]])\n        self.tok.train_from_iterator(self.chunk_dataset(dataset), trainer=trainer)\n        return self\n    \n    def tokenize(self, data):\n        tokenized_texts = []\n        for text in tqdm(data['text'].tolist()):\n            tokenized_texts.append(self.tok.encode(text))\n        return tokenized_texts\n    \ndef train_tokenizer(train, lm_data, train_old, test):\n\n    tokenizer_train_data = pd.concat([lm_data,train_old])\n    tok_data = pd.concat([ tokenizer_train_data[[\"text\"]],  test[[\"text\"]] ]).reset_index(drop=True)\n    vc_counters = {}\n    for vs in [5_000]: # for if needed to train multi vocab_size \n        bpe_tok = BPETokenizer(vs).train(tok_data)\n        ctr = Counter(chain(*[x.ids for x in bpe_tok.tokenize(tok_data)]))\n        vc_counters[vs] = (bpe_tok, ctr)\n        tqdm.write(f\"completed tokenization with {vs:,} vocab size\")\n    return vc_counters\n\ndef tokenize_datasets (vc_counters, train, lm_data, test):\n    \n    bpe_tok = vc_counters[5_000][0]\n    test_extend = pd.concat([lm_data,test])\n    tokenized_texts_train = [x.tokens for x in bpe_tok.tokenize(train)]\n    tokenized_texts_test = [x.tokens for x in bpe_tok.tokenize(test)]\n    tokenized_texts_lm_data = [x.tokens for x in bpe_tok.tokenize(lm_data)]\n    tokenized_texts_test2 = tokenized_texts_lm_data + tokenized_texts_test\n    \n    del tokenized_texts_lm_data\n    gc.collect()\n    \n    return tokenized_texts_train, tokenized_texts_test, tokenized_texts_test2\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:03:01.173595Z","iopub.execute_input":"2024-01-11T12:03:01.173925Z","iopub.status.idle":"2024-01-11T12:03:01.19183Z","shell.execute_reply.started":"2024-01-11T12:03:01.173882Z","shell.execute_reply":"2024-01-11T12:03:01.190659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def vectorizer related methods \ndef dummy1(text):\n    return text\n\ndef vectorizer_of_data(tokenized_texts_train,tokenized_texts_test,tokenized_texts_test2, min_diff, test):\n    len_test = len(test)\n    #print(len_test)\n    if len_test < 10:\n        min_diff = 0\n    \n    print(\"vectorizer - prepare vocab ..\")\n    vectorizer = TfidfVectorizer(ngram_range=(3, 6), lowercase=False, sublinear_tf=True, analyzer = 'word',min_df=min_diff, \n                                 tokenizer = dummy1, preprocessor = dummy1, token_pattern = None, strip_accents='unicode')\n    \n    vectorizer.fit(tokenized_texts_test2)\n    vocab = vectorizer.vocabulary_\n    \n    del vectorizer\n    gc.collect()\n    \n    vectorizer = TfidfVectorizer(ngram_range=(3, 6), lowercase=False, sublinear_tf=True, vocabulary=vocab, analyzer = 'word',\n                                 tokenizer = dummy1, preprocessor = dummy1, min_df=min_diff, token_pattern = None,\n                                 strip_accents='unicode')\n\n    print(\"vectorizer - fit transform on train ..\")\n\n    tf_train = vectorizer.fit_transform(tokenized_texts_train)\n    \n    print(\"vectorizer - transform on test ..\")\n\n    tf_test = vectorizer.transform(tokenized_texts_test)\n    \n    del tokenized_texts_test2\n    del tokenized_texts_test\n    del tokenized_texts_train\n    \n    del vectorizer\n    gc.collect()\n\n    return tf_train, tf_test","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:03:01.193646Z","iopub.execute_input":"2024-01-11T12:03:01.194028Z","iopub.status.idle":"2024-01-11T12:03:01.208179Z","shell.execute_reply.started":"2024-01-11T12:03:01.194Z","shell.execute_reply":"2024-01-11T12:03:01.206991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#methods to adopt learning from test data\n\ndef build_new_train_from_sub_all(final_preds_linear_tmp, test, X, Y):\n    \n    test.loc[:, 'generated'] = final_preds_linear_tmp\n    sorted_df = test.sort_values(by='generated', ascending=False)\n    top_rows = sorted_df.head(X).copy()\n    top_rows['label'] = 1\n    \n    # Select the bottom Y rows and set 'generated' to 0\n    bottom_rows = sorted_df.tail(Y).copy()\n    bottom_rows['label'] = 0\n    \n    # Concatenate the two subsets\n    train_from_sub = pd.concat([top_rows, bottom_rows])\n    \n    return train_from_sub\n\ndef build_new_train_from_sub_by_classs(final_preds_linear_tmp, test, X, Y):\n    test.loc[:, 'generated'] = final_preds_linear_tmp\n    class_dfs = {}\n    \n    # Iterate over each unique class value and create a separate DataFrame\n    for class_value in test['prompt_id'].unique():\n        class_dfs[class_value] = test[test['prompt_id'] == class_value]\n    #print(class_dfs[class_value])\n    \n    sorted_class_dfs = {class_value: df.sort_values(by='generated', ascending=False) for class_value, df in class_dfs.items()}\n    \n    new_class_dfs_with_generated = {}\n    \n    new_class_dfs_filtered = {}\n    for class_value, df in sorted_class_dfs.items():\n        if len(df) >= (X + Y):\n            top_rows = df.head(X).copy()\n            top_rows['label'] = 1\n            \n            bottom_rows = df.tail(Y).copy()\n            bottom_rows['label'] = 0\n            \n            combined = pd.concat([top_rows, bottom_rows], axis=0)\n            new_class_dfs_filtered[class_value] = combined\n            \n    if len(test) > 10:\n        train_from_sub = pd.concat(new_class_dfs_filtered.values(), ignore_index=True)\n    else:\n        train_from_sub = test\n        test['label'] = 1\n\n    return train_from_sub\n\n\ndef build_new_train_from_sub_add_all_data(final_preds_linear_tmp, test):\n    \n    test.loc[:, 'generated'] = final_preds_linear_tmp\n    median_label = test['generated'].median()\n    test['label'] = (test['generated'] >= median_label).astype(int)\n    train_from_sub = test.copy()\n    return train_from_sub\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:03:01.209788Z","iopub.execute_input":"2024-01-11T12:03:01.210126Z","iopub.status.idle":"2024-01-11T12:03:01.225808Z","shell.execute_reply.started":"2024-01-11T12:03:01.210098Z","shell.execute_reply":"2024-01-11T12:03:01.224695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define linear models training and prediction methods\ndef MaxAbsScalerTransform(tf_train,tf_test):\n    scaler = MaxAbsScaler()\n    X_train_scaled = scaler.fit_transform(tf_train)\n    X_test_scaled = scaler.transform(tf_test)\n    return X_train_scaled, X_test_scaled\n    \n\ndef get_predictions_linear_LinearSVR(X_train_scaled,X_test_scaled, y_train):\n    \n    #X_train_scaled, X_test_scaled = MaxAbsScalerTransform(tf_train,tf_test, y_train)\n    \n    model = Ridge(solver='sag',max_iter=10000,tol=1e-4, alpha = 1)\n    model.fit(X_train_scaled, y_train)\n    preds = model.predict(X_test_scaled.copy())\n    preds = sigmoid(preds)\n    \n    return preds\n\ndef get_predictions_linear_Ridge(X_train_scaled,X_test_scaled, y_train):\n    \n    #X_train_scaled, X_test_scaled = MaxAbsScalerTransform(tf_train,tf_test, y_train)\n    \n    model = Ridge(solver='sag',max_iter=8000,tol=1e-4, alpha = 1)\n    model.fit(X_train_scaled, y_train)\n    preds = model.predict(X_test_scaled.copy())\n    preds = sigmoid(preds)\n    \n    return preds","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:03:01.227423Z","iopub.execute_input":"2024-01-11T12:03:01.22779Z","iopub.status.idle":"2024-01-11T12:03:01.239223Z","shell.execute_reply.started":"2024-01-11T12:03:01.227763Z","shell.execute_reply":"2024-01-11T12:03:01.238368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define needed function and variables for transformer model used.\n\ndef preprocess_function_infer(examples):\n    return tokenizer_infer(examples['text'], max_length = 512 , padding=True, truncation=True)\n\ndef preprocess_function_train(examples):\n    return tokenizer_train(examples['text'], max_length=128, padding=True, truncation=True)\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    probs = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)\n    auc = roc_auc_score(labels, probs[:,1], multi_class='ovr')\n    return {\"roc_auc\": auc}\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:03:01.240558Z","iopub.execute_input":"2024-01-11T12:03:01.240853Z","iopub.status.idle":"2024-01-11T12:03:01.254464Z","shell.execute_reply.started":"2024-01-11T12:03:01.240828Z","shell.execute_reply":"2024-01-11T12:03:01.253516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define transformer model inference method\n\ndef get_predictions_tranformer(test):\n    #model_checkpoint_infer = \"/mnt/beegfs/xchen87/ai-gen/data/detect-llm-models/distilroberta-finetuned_v5/checkpoint-13542\"\n    \n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_infer, num_labels=2)\n    \n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    \n    test_ds = Dataset.from_pandas(test)\n    test_ds_enc = test_ds.map(preprocess_function_infer, batched=True)\n    trainer = Trainer(model,tokenizer=tokenizer_infer,)\n    test_preds = trainer.predict(test_ds_enc)\n    logits = test_preds.predictions\n    final_preds_trans = sigmoid(logits)[:,0]\n    \n    return final_preds_trans\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:03:01.258274Z","iopub.execute_input":"2024-01-11T12:03:01.25871Z","iopub.status.idle":"2024-01-11T12:03:01.265897Z","shell.execute_reply.started":"2024-01-11T12:03:01.258681Z","shell.execute_reply":"2024-01-11T12:03:01.264888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define transformer model training method\ndef train_inference_transformer_runtime(train,train_from_sub,test):\n    \n    #train = append_train_from_sub_phase(train, train_from_sub)\n    valid = train_from_sub\n    test = test[['id', 'text']]\n\n#     sk = StratifiedKFold(n_splits=10,shuffle=True,random_state=42)\n#     train0 = train\n#     for i, (tr,val) in enumerate(sk.split(train0,train0.label)):\n#         train = train0.iloc[tr]\n#         valid = train0.iloc[val]\n#         break\n        \n    train.text = train.text.fillna(\"\")\n    valid.text = valid.text.apply(lambda x: x.strip('\\n'))\n    train.text = train.text.apply(lambda x: x.strip('\\n'))\n    \n    ds_train = Dataset.from_pandas(train)\n    ds_valid = Dataset.from_pandas(valid)\n    \n    #tokenizer = AutoTokenizer.from_pretrained(model_checkpoint_base)\n    ds_train_enc = ds_train.map(preprocess_function_train, batched=True)\n    ds_valid_enc = ds_valid.map(preprocess_function_train, batched=True)\n    \n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_base, num_labels=2)\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    \n    early_stopping = EarlyStoppingCallback(early_stopping_patience=5)\n    \n    num_train_epochs=10.0\n    metric_name = \"roc_auc\"\n    model_name = \"distilroberta\"\n    batch_size = 2\n    \n    args = TrainingArguments(\n        f\"{model_name}-finetuned_v5\",\n        evaluation_strategy = \"epoch\",\n        save_strategy = \"epoch\",\n        learning_rate=2e-5,\n        lr_scheduler_type = \"cosine\",\n        save_safetensors = False,\n        optim=\"adamw_torch\",\n        per_device_train_batch_size=batch_size,\n        per_device_eval_batch_size=batch_size,\n        gradient_accumulation_steps=8,\n        num_train_epochs=num_train_epochs,\n        weight_decay=0.01,\n        load_best_model_at_end=True,\n        metric_for_best_model=metric_name,\n        save_total_limit=2,\n    )\n    \n    trainer = Trainer(\n        model,\n        args,\n        train_dataset=ds_train_enc,\n        eval_dataset=ds_valid_enc,\n        tokenizer=tokenizer_train,\n        callbacks = [early_stopping],\n        compute_metrics=compute_metrics\n    )\n    \n    trainer.train()\n    \n    trained_model = trainer.model\n    \n    test_ds = Dataset.from_pandas(test)\n    test_ds_enc = test_ds.map(preprocess_function_infer, batched=True)\n    trainer = Trainer(trained_model,tokenizer=tokenizer_train,)\n    test_preds = trainer.predict(test_ds_enc)\n    logits = test_preds.predictions\n    probs = sigmoid(logits)[:,1]\n    \n    return probs","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:03:01.267257Z","iopub.execute_input":"2024-01-11T12:03:01.267662Z","iopub.status.idle":"2024-01-11T12:03:01.283436Z","shell.execute_reply.started":"2024-01-11T12:03:01.267627Z","shell.execute_reply":"2024-01-11T12:03:01.282445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#methods for selecting weak rows from test data \n\ndef get_selected_rows_from_test(test, X, final_predictions, final_preds_trans):\n    test = read_test()\n    test['label'] = final_predictions\n    test['trans_label'] = final_preds_trans\n    test = test[['id','text', 'label','trans_label']].copy()\n\n\n    # Calculate the median of the label values\n    median_label = test['label'].median()\n\n    # Compute the absolute difference from the median for each row\n    test['difference_from_median'] = abs(test['label'] - median_label)\n\n    # Sort the DataFrame by this difference\n    test_sorted = test.sort_values('difference_from_median')\n\n    # Select the top X rows (replace X with your desired number of rows)\n    #X = 50  # For example, to select 10 rows\n    selected_rows = test_sorted.head(X)\n    selected_rows = selected_rows.drop(columns=['difference_from_median'])\n\n    return selected_rows\n\ndef get_similar_train_text(selected_rows, number_of_similar_rows, train, lm_data, train_old):\n    #train, lm_data, train_old = read_train(only_7_prompts = True)\n\n    print(\"train tokenizer ... iter: similarity\")\n    vs_counters = train_tokenizer(train, lm_data, train_old, selected_rows)\n\n    print(\"tokenize datasets ... iter: similarity\")\n    tokenized_texts_train, tokenized_texts_test, tokenized_texts_test2 = tokenize_datasets (vs_counters, train, lm_data, selected_rows)\n\n    print(\"verctorize datasets ... similarity \")\n    tfidf_train, tfidf_selected = vectorizer_of_data(tokenized_texts_train,tokenized_texts_test,tokenized_texts_test2, 2, test )\n\n    del tokenized_texts_test2, tokenized_texts_test, tokenized_texts_train, vs_counters\n    gc.collect()\n\n    similar_texts_dfs = []\n\n    # Iterate over the TF-IDF vectors of selected_rows\n    for i in range(tfidf_selected.shape[0]):\n        # Calculate cosine similarity between the selected text and all train texts\n        cosine_similarities = cosine_similarity(tfidf_selected[i], tfidf_train)\n\n        # Sort the similarities and get the top ones (e.g., top 10)\n        top_indices = cosine_similarities.argsort()[0][-number_of_similar_rows:]  # Adjust number as needed\n\n        # Retrieve the similar texts from train_df\n        similar_texts = train.iloc[top_indices]\n\n        # Add the DataFrame of similar texts to the list\n        similar_texts_dfs.append(similar_texts)\n\n    # Concatenate all the DataFrames in the list to form the final DataFrame\n    similar_texts_df = pd.concat(similar_texts_dfs).drop_duplicates()\n\n    return similar_texts_df","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:03:01.285134Z","iopub.execute_input":"2024-01-11T12:03:01.285582Z","iopub.status.idle":"2024-01-11T12:03:01.29925Z","shell.execute_reply.started":"2024-01-11T12:03:01.285548Z","shell.execute_reply":"2024-01-11T12:03:01.298307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define training X times strong procedures\n\ndef Train_Linear_X_Times_With_Infer_STRONG(number_of_times, X_TOP, Y_BOTTOM, test_data, only_7_prompts, trans_predictions, test_in,train_in, lm_data_in, train_old_in):\n    \n    final_preds_trans_DistilRoberta = trans_predictions\n    first_time = True\n    feedback_times = number_of_times\n    final_predictions = []\n    X = X_TOP\n    Y = Y_BOTTOM\n    \n    train_from_sub = read_test() #dummy def\n    \n    for i in range(1, feedback_times+1):\n        print(\"reading datasets ... iter: \", i)\n        #sub = read_sub()\n        #test = test_data  #read_dummy_test() #read_test()\n        #train, lm_data, train_old = read_train(only_7_prompts = only_7_prompts)\n        test = test_in.copy()\n        train = train_in.copy()\n        lm_data = lm_data_in.copy()\n        train_old = train_old_in.copy()\n    \n        if first_time == False:\n            train = append_train_from_sub_phase(train, train_from_sub)\n        \n        print(\"train tokenizer ... iter: \", i)\n        vs_counters = train_tokenizer(train, lm_data, train_old, test)\n    \n        print(\"tokenize datasets ... iter: \", i)\n        tokenized_texts_train, tokenized_texts_test, tokenized_texts_test2 = tokenize_datasets (vs_counters, train, lm_data, test)\n    \n        print(\"verctorize datasets ...iter: \", i)\n        tf_train, tf_test = vectorizer_of_data(tokenized_texts_train,tokenized_texts_test,tokenized_texts_test2, 2, test )\n        \n        del tokenized_texts_test2, tokenized_texts_test, tokenized_texts_train, vs_counters\n        gc.collect()\n    \n        print(\"predictions ... iter: \", i)\n        X_train_scaled, X_test_scaled = MaxAbsScalerTransform(tf_train,tf_test)\n        final_preds_linear_tmp = get_predictions_linear_LinearSVR(X_train_scaled, X_test_scaled, train['label'].values)\n    \n        del tf_train, tf_test, X_train_scaled, X_test_scaled \n        gc.collect()\n    \n        print(\"predeictions from iter : \",i, \" is : \", final_preds_linear_tmp)\n        \n        if first_time == True:\n            final_preds_phase_tmp = 0.5*final_preds_linear_tmp + 0.5*final_preds_trans_DistilRoberta\n        else:\n            final_preds_phase_tmp = 0.70*final_preds_linear_tmp + 0.30*final_preds_trans_DistilRoberta\n    \n        #final_preds_phase_tmp = 0.5*final_preds_linear_tmp + 0.5*final_preds_trans_DistilRoberta\n    \n        print(\"final predeictions from iter : \",i, \" is : \", final_preds_phase_tmp)\n\n        final_predictions = final_preds_phase_tmp #final_preds_phase_tmp\n    \n        train_from_sub = build_new_train_from_sub_all(final_preds_phase_tmp, test, X, Y)\n        X = X + int(200/i)\n        Y = Y + int(200/i)\n        print(\"new x,y: \",X,Y)\n    \n        first_time = False\n        \n    return final_predictions, train_from_sub\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:03:01.300431Z","iopub.execute_input":"2024-01-11T12:03:01.300721Z","iopub.status.idle":"2024-01-11T12:03:01.317528Z","shell.execute_reply.started":"2024-01-11T12:03:01.300696Z","shell.execute_reply":"2024-01-11T12:03:01.316563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define training X times weak procedures\ndef Train_Linear_With_Infer_WEAK(X_MIDDLE,SIMILAR_ROWS, test_data, only_7_prompts, final_predictions, final_preds_trans, train, lm_data, train_old):\n    \n    test = test_data\n    selected_rows = get_selected_rows_from_test(test,X_MIDDLE,final_predictions, final_preds_trans)\n    similar_texts_df = get_similar_train_text(selected_rows, SIMILAR_ROWS,train, lm_data, train_old)\n    \n    #train, lm_data, train_old = read_train(only_7_prompts = only_7_prompts)\n    train = similar_texts_df\n    train = train.drop_duplicates(subset='text', keep='first')\n    train = train[['text', 'label']]\n    train.reset_index(drop=True, inplace=True)\n        \n    test = selected_rows \n        \n    print(\"train tokenizer ... iter: over weak\")\n    vs_counters = train_tokenizer(train, lm_data, train_old, test)\n        \n    print(\"tokenize datasets ... iter: over weak\")\n    tokenized_texts_train, tokenized_texts_test, tokenized_texts_test2 = tokenize_datasets (vs_counters, train, lm_data, test)\n        \n    print(\"verctorize datasets ...iter: over weak\")\n    tf_train, tf_test = vectorizer_of_data(tokenized_texts_train,tokenized_texts_test,tokenized_texts_test2, 2 ,test)\n        \n    del tokenized_texts_test2, tokenized_texts_test, tokenized_texts_train, vs_counters\n    gc.collect()\n        \n    print(\"predictions ... iter: over weak\")\n    X_train_scaled, X_test_scaled = MaxAbsScalerTransform(tf_train,tf_test)\n    preds_linear_weak= get_predictions_linear_LinearSVR(X_train_scaled, X_test_scaled, train['label'].values)\n    \n    del tf_train, tf_test, X_train_scaled, X_test_scaled \n    gc.collect()\n    \n    trans_sel_pred = selected_rows['trans_label']\n    trans_sel_pred = trans_sel_pred.values\n    selected_rows_final_pred = 0.5*preds_linear_weak +0.5*trans_sel_pred\n    selected_rows['label'] = selected_rows_final_pred\n    \n    test = read_test()\n    test['label'] = final_predictions\n    \n    test.set_index('id', inplace=True, drop=True)\n    selected_rows.set_index('id', inplace=True, drop=True)\n    # Update test_df with the new label values from selected_rows\n    test.update(selected_rows)\n    # Reset index if you want to revert 'id' back to a column\n    test.reset_index(inplace=True)\n\n    return test['label']\n","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:03:01.318911Z","iopub.execute_input":"2024-01-11T12:03:01.319193Z","iopub.status.idle":"2024-01-11T12:03:01.335286Z","shell.execute_reply.started":"2024-01-11T12:03:01.319167Z","shell.execute_reply":"2024-01-11T12:03:01.334252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_for_prompt_names():\n    train_for_cat, lm_data, train_old = read_train_all()\n    tfidf_cat = TfidfVectorizer()\n    X_cat = tfidf_cat.fit_transform(train_for_cat['text'])\n    X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X_cat, train_for_cat['prompt_name'], test_size=0.05, random_state=42)\n    model_cat = LogisticRegression(max_iter=1000)\n    model_cat.fit(X_train_cat, y_train_cat)\n    return tfidf_cat, model_cat\n\n\ndef get_test_prompt_names(test,tfidf_cat,model_cat):\n    unique_prompt_ids_count = test['prompt_id'].nunique()\n    print(\"There are : \", unique_prompt_ids_count, \" prompts in the test data\")\n\n    predefined_prompt_names_list = ['Facial action coding system', 'Driverless cars', 'Exploring Venus', 'The Face on Mars', 'A Cowboy Who Rode the Waves']\n    if len(test) == 3:\n        print(\"select predefined prompts .. \")\n        return predefined_prompt_names_list\n\n    # predict test cats category \n    test_cats = tfidf_cat.transform(test['text'])\n    test_prompt_names = model_cat.predict(test_cats)\n    test['prompt_name'] = test_prompt_names\n    # get top n\n    prompt_counts = test['prompt_name'].value_counts()\n    top_n_prompts = prompt_counts.head(unique_prompt_ids_count).index.tolist()\n    return top_n_prompts\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check if run is for save or submit\nsubmit_mode = True\nif len(pd.read_csv('/mnt/beegfs/xchen87/ai-gen/data/llm-detect-ai-generated-text/test_essays.csv')) == 3:\n    submit_mode = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_mode = True\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if submit_mode == True:\n    print(\"Predict the prompt names used in test ...\")\n    test = read_test()\n    tfidf_cat, model_cat = train_for_prompt_names()\n    top_n_prompts = get_test_prompt_names(test,tfidf_cat,model_cat)\n    print(top_n_prompts)\n    \n    print(\"done ...\")\n    print(\"select training data based on the prompt names .. \")\n    \n    train_all, lm_data, train_old_all = read_train_all()\n    train = train_all[train_all['prompt_name'].isin(top_n_prompts)]\n    train = pd.concat([train, train_old_all] , ignore_index=True)\n    #lm_data = lm_data_all[lm_data_all['prompt_name'].isin(top_n_prompts)]\n    train_old = train_old_all.copy()\n    \n    test = read_test()\n    #train, lm_data, train_old = read_train(only_7_prompts = True)\n    \n    print(\"spelling process...\")\n    train['text'] = train['text'].progress_apply(sentence_correcter)\n    lm_data['text'] = lm_data['text'].progress_apply(sentence_correcter)\n    train_old['text'] = train_old['text'].progress_apply(sentence_correcter)\n    test['text'] = test['text'].progress_apply(sentence_correcter)\n\n    print(\"predictions from transformer\")\n    final_preds_trans_DistilRoberta = get_predictions_tranformer(read_test()) # you may want to try with corrected test data \n    print (\"Predictions from Trans: \", final_preds_trans_DistilRoberta)\n    final_predictions_strong, train_from_sub = Train_Linear_X_Times_With_Infer_STRONG(5,1000,1500,test,True, final_preds_trans_DistilRoberta, test,train, lm_data, train_old)\n    \n#     print (\"Predictions from Strong: \", final_predictions_strong)\n#     final_predictions_strong_weak = Train_Linear_With_Infer_WEAK(50,100, test, True, final_predictions_strong, final_preds_trans_DistilRoberta, train, lm_data, train_old)\n#     print (\"Predictions from Weak: \", final_predictions_strong_weak)\n    \n#     #train, lm_data, train_old = read_train(only_7_prompts = True)  #this might affect the output if was droped\n#     final_preds_trans_DistilRoberta_with_test_feedback = train_inference_transformer_runtime(train,train_from_sub,test)\n#     print (\"Predictions from trans with feedback: \", final_preds_trans_DistilRoberta_with_test_feedback)\n    \n#     final_predictions_deep = 0.8*final_predictions_strong_weak+0.2*final_preds_trans_DistilRoberta_with_test_feedback\n    \n    sub = read_sub() #read_dummy_test() #read_sub()\n\n    sub['generated'] = final_predictions_strong\n    sub.to_csv('submission.csv', index=False)\n    \nelse:\n    sub = read_sub()\n    sub['generated'] = 1\n    sub.to_csv('submission.csv', index=False)\n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-11T12:03:01.360935Z","iopub.execute_input":"2024-01-11T12:03:01.361302Z","iopub.status.idle":"2024-01-11T12:36:17.115802Z","shell.execute_reply.started":"2024-01-11T12:03:01.36126Z","shell.execute_reply":"2024-01-11T12:36:17.11437Z"},"trusted":true},"execution_count":null,"outputs":[]}]}