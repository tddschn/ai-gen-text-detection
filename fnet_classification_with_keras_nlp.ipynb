{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Text Classification using FNet\n",
    "\n",
    "**Author:** [Abheesht Sharma](https://github.com/abheesht17/)<br>\n",
    "**Date created:** 2022/06/01<br>\n",
    "**Last modified:** 2022/12/21<br>\n",
    "**Description:** Text Classification on the IMDb Dataset using `keras_nlp.layers.FNetEncoder` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this example, we will demonstrate the ability of FNet to achieve comparable\n",
    "results with a vanilla Transformer model on the text classification task.\n",
    "We will be using the IMDb dataset, which is a\n",
    "collection of movie reviews labelled either positive or negative (sentiment\n",
    "analysis).\n",
    "\n",
    "To build the tokenizer, model, etc., we will use components from\n",
    "[KerasNLP](https://github.com/keras-team/keras-nlp). KerasNLP makes life easier\n",
    "for people who want to build NLP pipelines! :)\n",
    "\n",
    "### Model\n",
    "\n",
    "Transformer-based language models (LMs) such as BERT, RoBERTa, XLNet, etc. have\n",
    "demonstrated the effectiveness of the self-attention mechanism for computing\n",
    "rich embeddings for input text. However, the self-attention mechanism is an\n",
    "expensive operation, with a time complexity of `O(n^2)`, where `n` is the number\n",
    "of tokens in the input. Hence, there has been an effort to reduce the time\n",
    "complexity of the self-attention mechanism and improve performance without\n",
    "sacrificing the quality of results.\n",
    "\n",
    "In 2020, a paper titled\n",
    "[FNet: Mixing Tokens with Fourier Transforms](https://arxiv.org/abs/2105.03824)\n",
    "replaced the self-attention layer in BERT with a simple Fourier Transform layer\n",
    "for \"token mixing\". This resulted in comparable accuracy and a speed-up during\n",
    "training. In particular, a couple of points from the paper stand out:\n",
    "\n",
    "* The authors claim that FNet is 80% faster than BERT on GPUs and 70% faster on\n",
    "TPUs. The reason for this speed-up is two-fold: a) the Fourier Transform layer\n",
    "is unparametrized, it does not have any parameters, and b) the authors use Fast\n",
    "Fourier Transform (FFT); this reduces the time complexity from `O(n^2)`\n",
    "(in the case of self-attention) to `O(n log n)`.\n",
    "* FNet manages to achieve 92-97% of the accuracy of BERT on the GLUE benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Before we start with the implementation, let's import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!pip install -q --upgrade keras-nlp\n",
    "!pip install -q --upgrade keras  # Upgrade to Keras 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xchen87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/beegfs/xchen87/keras-tutorial\n",
      "/mnt/beegfs/xchen87/keras-tutorial\n"
     ]
    }
   ],
   "source": [
    "# get pwd\n",
    "!pwd\n",
    "!mkdir -pv /mnt/beegfs/xchen87/keras-tutorial\n",
    "# set pwd to /mnt/beegfs/xchen87/keras-tutorial\n",
    "%cd /mnt/beegfs/xchen87/keras-tutorial\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 07:42:37.781074: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-08 07:42:37.781131: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-08 07:42:37.853133: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-08 07:42:38.025359: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-08 07:42:44.968741: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import keras_nlp\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's also define our hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "VOCAB_SIZE = 15000\n",
    "\n",
    "EMBED_DIM = 128\n",
    "INTERMEDIATE_DIM = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Loading the dataset\n",
    "\n",
    "First, let's download the IMDB dataset and extract it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-08 07:44:28--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘aclImdb_v1.tar.gz’\n",
      "\n",
      "aclImdb_v1.tar.gz   100%[===================>]  80.23M   370KB/s    in 3m 36s  \n",
      "\n",
      "2024-03-08 07:48:04 (380 KB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xzf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Samples are present in the form of text files. Let's inspect the structure of\n",
    "the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imdb.vocab', 'imdbEr.txt', 'train', 'test', 'README']\n",
      "['neg', 'unsup', 'urls_unsup.txt', 'pos', 'unsupBow.feat', 'labeledBow.feat', 'urls_neg.txt', 'urls_pos.txt']\n",
      "['neg', 'pos', 'labeledBow.feat', 'urls_neg.txt', 'urls_pos.txt']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"./aclImdb\"))\n",
    "print(os.listdir(\"./aclImdb/train\"))\n",
    "print(os.listdir(\"./aclImdb/test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The directory contains two sub-directories: `train` and `test`. Each subdirectory\n",
    "in turn contains two folders: `pos` and `neg` for positive and negative reviews,\n",
    "respectively. Before we load the dataset, let's delete the `./aclImdb/train/unsup`\n",
    "folder since it has unlabelled samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!rm -rf aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We'll use the `keras.utils.text_dataset_from_directory` utility to generate\n",
    "our labelled `tf.data.Dataset` dataset from text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 07:51:10.946494: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 07:51:11.059706: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 07:51:11.061185: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 07:51:11.072784: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 07:51:11.074208: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 07:51:11.075613: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 07:51:11.211473: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 07:51:11.212984: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 07:51:11.214408: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 07:51:11.215793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79086 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:81:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    ")\n",
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    ")\n",
    "test_ds = keras.utils.text_dataset_from_directory(\"aclImdb/test\", batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We will now convert the text to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (tf.strings.lower(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's print a few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n",
      "(64,)\n",
      "b\"nobody said movies had to be realistic did they? i really liked this movie because i remember when i first saw it in junior high. for all the kids who remember the pmrc and albums before there were warning stickers, it's a cool story for all those kids who were part of the mid to late 80's headbanger crowd.\"\n",
      "1\n",
      "b\"a different look at horror. the styling differences between american and russian films is interesting. however from my american perspective this movie just wasn't that good. the protagonist, marie played by anastasia hille wasn't a pleasant character and i had a hard time identifying with her. she was disagreeable most of the time and confused for much of what little time was left. also too much time was spent in bringing her to the main location of the film. then a long time passed before any real suspense built up. once that happened it seemed volume was used as the main effect which was more annoying than anything else. the concept was more original than most direct-to-video movies and they didn't use sex to make up for a thin plot. all in all i'd recommend it for renting, but not for theater goers.\"\n",
      "0\n",
      "b'the movie \"atlantis: the lost empire\" is a shining gem in the rubble of films produced by the disney studios recently. parents who have had to sit through \"the jungle book 2\" or even a pokemon movie will surely appreciate this one.<br /><br />the film is one of few to attempt at an original story; previous feature films were merely re tellings of existing stories. films such as \"toy story\", \"finding nemo\", and \"monsters inc.\" all do the same, but it must be noted that all were made by pixar and only distributed by disney. recent films from the disney studios are mostly released direct to video, and are sequels to an existing successful film. the quality of those films is given way to the profitability. a new era started with \"atlantis\" following it were \"mulan\", \"lilo & stitch\", and most recently \"open range\". the writers have created all original story lines instead of the fairy tales of the past.<br /><br />a good portion of the movie is devoted to the quest to find atlantis, a task that has captured the imagination of many for hundreds of years. including that of young milo thatch, voiced by michael j. fox. milo is employed by a museum in washington d.c.. his grandfather was a renowned archaeologist, who had devoted his life to discovering atlantis. this was seen as a waste by his peers, and they wish milo to not follow in his footsteps. after failing to convince the museum board of directors to sponsor his expedition, milo comes home to find a woman in his darkened apartment. she takes him to her employer, a mr. whitmore. whitmore was a close friend of milo\\'s grandfather, and wishes to send milo with a team to locate atlantis. mr. whitmore is very wealth and has paid for the best of everything. the crew that is to accompany him is the same as his grandfathers. the journey is filled with many great obstacles to overcome and is great fun to watch. the viewer finds themselves caught up in if they will reach atlantis. the plot takes an unexpected turn after the discovery atlantis, not just the discovery of people. it is enough to keep the interest of the older audience.<br /><br />the animators have done a wonderful job in then depth of the animation. the movie is very successful in blending traditional animation with computer generated images. a feat not easily achieved, most audiences are quick to notice the difference in the two. the characters are believably human. there are some nice chase type scenes, with lots of action going on. a few lulls are filled with jokes that the children just may not get.<br /><br />the creativity of the writers really shines through. the culture of atlantis is richly developed, including an entire language. the film uses references to atlantis from historical sources, such as plato. the disappearance of atlantis from the world is explained. believable, if by a younger audience, that magic really does exist. the powers of the people of atlantis are not exactly presented as magic, but can best be described in this way.<br /><br />although set in 1914 the level of technology used is unrealistic. the voyage is in a submarine very reminiscent of captain nemo\\'s nautilus, complete with sub pods that fire torpedoes. the giant diggers are driven by steam boilers so they did try for some era technology. the female characters are empowered in a way that women of the age would not have been, even holding roles in leadership. this is not a bad thing. it gives a good role model for my daughter to look to, rather than an all male cast.<br /><br />one reason this film is a favorite of mine over other disney films is that there is not one single song, ever. a tradition that began with the first feature film, \"snow white\", and carried on through to \"the lion king\", almost every disney film is full of upbeat songs. this is great and all, what would the seven dwarfs be without \"hi ho!\"? after the millionth time through it\\'d almost be better without, but this one spares the parent. not once does every single person on the screen suddenly know the words to a song that no one has ever heard before and break out in song. i for one am grateful.<br /><br />the storyline and depth of animation is sure to keep the attention of both parent and child alike. it is a film i am willing to watch again and again with my children.'\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    print(text_batch.numpy().shape)\n",
    "    print(label_batch.numpy().shape)\n",
    "    for i in range(3):\n",
    "        print(text_batch.numpy()[i])\n",
    "        print(label_batch.numpy()[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tokenizing the data\n",
    "\n",
    "We'll be using the `keras_nlp.tokenizers.WordPieceTokenizer` layer to tokenize\n",
    "the text. `keras_nlp.tokenizers.WordPieceTokenizer` takes a WordPiece vocabulary\n",
    "and has functions for tokenizing the text, and detokenizing sequences of tokens.\n",
    "\n",
    "Before we define the tokenizer, we first need to train it on the dataset\n",
    "we have. The WordPiece tokenization algorithm is a subword tokenization algorithm;\n",
    "training it on a corpus gives us a vocabulary of subwords. A subword tokenizer\n",
    "is a compromise between word tokenizers (word tokenizers need very large\n",
    "vocabularies for good coverage of input words), and character tokenizers\n",
    "(characters don't really encode meaning like words do). Luckily, KerasNLP\n",
    "makes it very simple to train WordPiece on a corpus with the\n",
    "`keras_nlp.tokenizers.compute_word_piece_vocabulary` utility.\n",
    "\n",
    "Note: The official implementation of FNet uses the SentencePiece Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_word_piece(ds, vocab_size, reserved_tokens):\n",
    "    word_piece_ds = ds.unbatch().map(lambda x, y: x)\n",
    "    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
    "        word_piece_ds.batch(1000).prefetch(2),\n",
    "        vocabulary_size=vocab_size,\n",
    "        reserved_tokens=reserved_tokens,\n",
    "    )\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Every vocabulary has a few special, reserved tokens. We have two such tokens:\n",
    "\n",
    "- `\"[PAD]\"` - Padding token. Padding tokens are appended to the input sequence length\n",
    "when the input sequence length is shorter than the maximum sequence length.\n",
    "- `\"[UNK]\"` - Unknown token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "reserved_tokens = [\"[PAD]\", \"[UNK]\"]\n",
    "train_sentences = [element[0] for element in train_ds]\n",
    "vocab = train_word_piece(train_ds, VOCAB_SIZE, reserved_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's see some tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:  ['à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens: \", vocab[100:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest tokens:  ['characterizations', 'characterization', 'incomprehensible', 'characterisation', 'enthusiastically', 'unintentionally', 'cinematographer', 'straightforward', 'characteristics', 'interpretations']\n",
      "Middle tokens:  ['tonight', 'travels', 'yelling', 'designs', 'emperor', 'illegal', 'judging', 'montana', 'classes', 'directs']\n"
     ]
    }
   ],
   "source": [
    "# print the top 10 longest tokens\n",
    "sorted_vocab = sorted(vocab, key=lambda x: len(x), reverse=True)\n",
    "print(\"Longest tokens: \", sorted_vocab[:10])\n",
    "# print 10 in the middle\n",
    "print(\"Middle tokens: \", sorted_vocab[5000:5010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histogram of token length\n",
    "# use seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "token_lengths = [len(token) for token in vocab]\n",
    "sns.histplot(token_lengths, bins=50)\n",
    "plt.xlabel(\"Token length\")\n",
    "plt.ylabel(\"Number of tokens\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Now, let's define the tokenizer. We will configure the tokenizer with the\n",
    "the vocabularies trained above. We will define a maximum sequence length so that\n",
    "all sequences are padded to the same length, if the length of the sequence is\n",
    "less than the specified sequence length. Otherwise, the sequence is truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=vocab,\n",
    "    lowercase=False,\n",
    "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's try and tokenize a sample from our dataset! To verify whether the text has\n",
    "been tokenized correctly, we can also detokenize the list of tokens back to the\n",
    "original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  tf.Tensor(b\"prot\\xc3\\xa9g\\xc3\\xa9 runs in a linear fashion; expect no fast-paced action, and neither will you find yourself with baited breath because there are simply no seating-on-the-edge moments.<br /><br />there is not much of a crux, so don't expect one either. i would not fault the acting - the show would have been much worst if not for wu's acting which was the film's only saving grace. and, oh that cute little girl too.<br /><br />the humour is at best, weak, and the show must as well pass off as an anti-drug campaign which employs the usual shock-tactic (esp in the scenes with zhang) to tell us stuff that we already know - i.e. drugs break up families, heroin drives you crazy, it is not so easy to wean off, you will fall into a vicious cycle.<br /><br />i know it may seem all a little harsh, but i feel that the show is far from seamless and somewhat patchy (*spoiler alert*: take for example when andy lau got brought to the police station: what? we were just told 'oh we have all the tapes and evidence against you since 1997', and that is how he got caught. nope, no chasing-car action, just a jump-of-scene, which kind of undermined wu's role as an undercover in the first place.) i suspect the lack of creativity is attributed to the fact that it is after all, a production of mediacorp raintree - a singaporean production film company.\", shape=(), dtype=string)\n",
      "Tokens:  tf.Tensor(\n",
      "[ 3732   398  3469 12865  1315   144    40  6915  1794    28   669   192\n",
      "   843    14  2046   343    13   138  1222   213   155   306   774   151\n",
      "  9725   257  2978   220   173   158   472   192  2454   239    14   154\n",
      "    14   137    14  1469   523    15    29   142    16    31    29   142\n",
      "    16    31   173   141   156   207   139    40    42 11751  1214    13\n",
      "   170   223     8    59   669   162   483    15    48   194   156  2405\n",
      "   137   246    14   137   255   194   160   210   207   387   180   156\n",
      "   149  8510     8    58   246   195   147   137   153     8    58   197\n",
      "  2065  1816    15   138    13   579   146  1187   250   377   231    15\n",
      "    29   142    16    31    29   142    16    31   137  1470   141   165\n",
      "   251    13   953    13   138   137   255   345   148   205  1486   260\n",
      "   148   168  1377    14  1586  6059   195 11186   137   779  1678    14\n",
      "    59 10718     9 13529   144   137   276   151 12052    10   140   519\n",
      "   317   675   146   202   606   256    14    48    15    44    15  1850\n",
      "  1143   189  2344    13 11213  3357   155  1078    13   143   141   156\n",
      "   170   911   140   202   771   260    13   155   213   925   217    40\n",
      "  4431  7832    15    29   142    16    31    29   142    16    31    48\n",
      "   256   143   338   448   163    40   250  2793    13   152    48   370\n",
      "   146   137   255   141   367   171 14257   138   812 10633   292     9\n",
      "    11  1491  4658    11    27   334   149   603   186  1927  1247   978\n",
      "   327  1019   140   137   712  1940    27   181    32   202   204   176\n",
      "   715     8   579   202   160   163   137  6192   138  2615   582   155\n",
      "   373  5448     8    13   138   146   141   221   157   327  1205    15\n",
      "  6826    13   192  3488    14   663   343    13   176    40  1953    14\n",
      "   139    14   271    13   195   380   139   619 12439  8510     8    58\n",
      "   357   148   168  9890   144   137   216   408    15    10    48  2000\n",
      "   137   711   139  5279   141 11125   140   137   328   146   143   141\n",
      "   234   163    13    40   503   139  1947 12062   895  2538  9272   314\n",
      "    14    40  2167  5915  4602   771   503   153  1291    15     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0], shape=(512,), dtype=int32)\n",
      "Recovered text after detokenizing:  tf.Tensor(b\"prot\\xc3\\xa9g\\xc3\\xa9 runs in a linear fashion ; expect no fast - paced action , and neither will you find yourself with baited breath because there are simply no seating - on - the - edge moments . < br / > < br / > there is not much of a crux , so don ' t expect one either . i would not fault the acting - the show would have been much worst if not for wu ' s acting which was the film ' s only saving grace . and , oh that cute little girl too . < br / > < br / > the humour is at best , weak , and the show must as well pass off as an anti - drug campaign which employs the usual shock - tactic ( esp in the scenes with zhang ) to tell us stuff that we already know - i . e . drugs break up families , heroin drives you crazy , it is not so easy to wean off , you will fall into a vicious cycle . < br / > < br / > i know it may seem all a little harsh , but i feel that the show is far from seamless and somewhat patchy ( * spoiler alert * : take for example when andy lau got brought to the police station : what ? we were just told ' oh we have all the tapes and evidence against you since 1997 ' , and that is how he got caught . nope , no chasing - car action , just a jump - of - scene , which kind of undermined wu ' s role as an undercover in the first place . ) i suspect the lack of creativity is attributed to the fact that it is after all , a production of mediacorp raintree - a singaporean production film company . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "input_sentence_ex = train_ds.take(1).get_single_element()[0][0]\n",
    "input_tokens_ex = tokenizer(input_sentence_ex)\n",
    "\n",
    "print(\"Sentence: \", input_sentence_ex)\n",
    "print(\"Tokens: \", input_tokens_ex)\n",
    "print(\"Recovered text after detokenizing: \", tokenizer.detokenize(input_tokens_ex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_tokens_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Formatting the dataset\n",
    "\n",
    "Next, we'll format our datasets in the form that will be fed to the models. We\n",
    "need to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def format_dataset(sentence, label):\n",
    "    sentence = tokenizer(sentence)\n",
    "    return ({\"input_ids\": sentence}, label)\n",
    "\n",
    "\n",
    "def make_dataset(dataset):\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset.shuffle(512).prefetch(16).cache()\n",
    "\n",
    "\n",
    "train_ds = make_dataset(train_ds)\n",
    "val_ds = make_dataset(val_ds)\n",
    "test_ds = make_dataset(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Building the model\n",
    "\n",
    "Now, let's move on to the exciting part - defining our model!\n",
    "We first need an embedding layer, i.e., a layer that maps every token in the input\n",
    "sequence to a vector. This embedding layer can be initialised randomly. We also\n",
    "need a positional embedding layer which encodes the word order in the sequence.\n",
    "The convention is to add, i.e., sum, these two embeddings. KerasNLP has a\n",
    "`keras_nlp.layers.TokenAndPositionEmbedding ` layer which does all of the above\n",
    "steps for us.\n",
    "\n",
    "Our FNet classification model consists of three `keras_nlp.layers.FNetEncoder`\n",
    "layers with a `keras.layers.Dense` layer on top.\n",
    "\n",
    "Note: For FNet, masking the padding tokens has a minimal effect on results. In the\n",
    "official implementation, the padding tokens are not masked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "input_ids = keras.Input(shape=(None,), dtype=\"int64\", name=\"input_ids\")\n",
    "\n",
    "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "    vocabulary_size=VOCAB_SIZE,\n",
    "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    embedding_dim=EMBED_DIM,\n",
    "    mask_zero=True,\n",
    ")(input_ids)\n",
    "\n",
    "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
    "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
    "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
    "\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "fnet_classifier = keras.Model(input_ids, outputs, name=\"fnet_classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Training our model\n",
    "\n",
    "We'll use accuracy to monitor training progress on the validation data. Let's\n",
    "train our model for 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fnet_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_ids (InputLayer)      [(None, None)]            0         \n",
      "                                                                 \n",
      " token_and_position_embeddi  (None, None, 128)         1985536   \n",
      " ng (TokenAndPositionEmbedd                                      \n",
      " ing)                                                            \n",
      "                                                                 \n",
      " f_net_encoder (FNetEncoder  (None, None, 128)         132224    \n",
      " )                                                               \n",
      "                                                                 \n",
      " f_net_encoder_1 (FNetEncod  (None, None, 128)         132224    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " f_net_encoder_2 (FNetEncod  (None, None, 128)         132224    \n",
      " er)                                                             \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 128)               0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2382337 (9.09 MB)\n",
      "Trainable params: 2382337 (9.09 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 08:07:11.956936: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fc3c45e8090 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-08 08:07:11.956972: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2024-03-08 08:07:12.095855: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-08 08:07:13.030724: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1709903233.151390 1792711 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 39s 83ms/step - loss: 0.5070 - accuracy: 0.7163 - val_loss: 0.3341 - val_accuracy: 0.8532\n",
      "Epoch 2/3\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2480 - accuracy: 0.8998 - val_loss: 0.3671 - val_accuracy: 0.8518\n",
      "Epoch 3/3\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1564 - accuracy: 0.9413 - val_loss: 0.3660 - val_accuracy: 0.8634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc4ec11c220>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnet_classifier.summary()\n",
    "fnet_classifier.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "fnet_classifier.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We obtain a train accuracy of around 92% and a validation accuracy of around\n",
    "85%. Moreover, for 3 epochs, it takes around 86 seconds to train the model\n",
    "(on Colab with a 16 GB Tesla T4 GPU).\n",
    "\n",
    "Let's calculate the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 5s 6ms/step - loss: 0.3869 - accuracy: 0.8497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.386921763420105, 0.8497200012207031]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnet_classifier.evaluate(test_ds, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Comparison with Transformer model\n",
    "\n",
    "Let's compare our FNet Classifier model with a Transformer Classifier model. We\n",
    "keep all the parameters/hyperparameters the same. For example, we use three\n",
    "`TransformerEncoder` layers.\n",
    "\n",
    "We set the number of heads to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_ids (InputLayer)      [(None, None)]            0         \n",
      "                                                                 \n",
      " token_and_position_embeddi  (None, None, 128)         1985536   \n",
      " ng_1 (TokenAndPositionEmbe                                      \n",
      " dding)                                                          \n",
      "                                                                 \n",
      " transformer_encoder (Trans  (None, None, 128)         198272    \n",
      " formerEncoder)                                                  \n",
      "                                                                 \n",
      " transformer_encoder_1 (Tra  (None, None, 128)         198272    \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " transformer_encoder_2 (Tra  (None, None, 128)         198272    \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_average_pooling1d_1  (None, 128)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2580481 (9.84 MB)\n",
      "Trainable params: 2580481 (9.84 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "313/313 [==============================] - 34s 87ms/step - loss: 0.4480 - accuracy: 0.7759 - val_loss: 0.2809 - val_accuracy: 0.8852\n",
      "Epoch 2/3\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.2180 - accuracy: 0.9171 - val_loss: 0.3090 - val_accuracy: 0.8760\n",
      "Epoch 3/3\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.1636 - accuracy: 0.9390 - val_loss: 0.4015 - val_accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc3e1e11c60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_HEADS = 2\n",
    "input_ids = keras.Input(shape=(None,), dtype=\"int64\", name=\"input_ids\")\n",
    "\n",
    "\n",
    "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "    vocabulary_size=VOCAB_SIZE,\n",
    "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    embedding_dim=EMBED_DIM,\n",
    "    mask_zero=True,\n",
    ")(input_ids)\n",
    "\n",
    "x = keras_nlp.layers.TransformerEncoder(\n",
    "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
    ")(inputs=x)\n",
    "x = keras_nlp.layers.TransformerEncoder(\n",
    "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
    ")(inputs=x)\n",
    "x = keras_nlp.layers.TransformerEncoder(\n",
    "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
    ")(inputs=x)\n",
    "\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "transformer_classifier = keras.Model(input_ids, outputs, name=\"transformer_classifier\")\n",
    "\n",
    "\n",
    "transformer_classifier.summary()\n",
    "transformer_classifier.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "transformer_classifier.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We obtain a train accuracy of around 94% and a validation accuracy of around\n",
    "86.5%. It takes around 146 seconds to train the model (on Colab with a 16 GB Tesla\n",
    "T4 GPU).\n",
    "\n",
    "Let's calculate the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 5s 12ms/step - loss: 0.4395 - accuracy: 0.8517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43950578570365906, 0.8516799807548523]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_classifier.evaluate(test_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's make a table and compare the two models. We can see that FNet\n",
    "significantly speeds up our run time (1.7x), with only a small sacrifice in\n",
    "overall accuracy (drop of 0.75%).\n",
    "\n",
    "|                         | **FNet Classifier** | **Transformer Classifier** |\n",
    "|:-----------------------:|:-------------------:|:--------------------------:|\n",
    "|    **Training Time**    |      86 seconds     |         146 seconds        |\n",
    "|    **Train Accuracy**   |        92.34%       |           93.85%           |\n",
    "| **Validation Accuracy** |        85.21%       |           86.42%           |\n",
    "|    **Test Accuracy**    |        83.94%       |           84.69%           |\n",
    "|       **#Params**       |      2,321,921      |          2,520,065         |"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fnet_classification_with_keras_nlp",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
